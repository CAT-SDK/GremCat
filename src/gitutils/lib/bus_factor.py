# -*- coding: utf-8 -*-
"""meercat_bus_factor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BejHJ-HuCISrOfgwvivzOY9WBJDHipJk

# First we will bring in one of the GremCat libraries

This is the library that provides the `get_commits` function, which will translate a portion of a project database into a pandas `DataFrame`.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install uo-puddles
# from uo_puddles.gremcat_df import *

"""# If you want to update your database

As reminder, here is a description of how to update your database on whatever server you are using to host it: https://github.com/HPCL/ideas-uo/tree/main/database.

# Next we will install the link to your database

Note that this assumes that you have successfully built a database as detailed by the scripts at `<fill in link>`.
"""

import MySQLdb
from thefuzz import process, fuzz  #https://github.com/seatgeek/thefuzz
import textdistance as td

from uo_puddles.gremcat_df import *

#host = "arya.cs.uoregon.edu"
#port = 3331
#user = "ideas_user"
#database = "ideas_db"
#password = getpass('Enter the password value: ')

#mydb = MySQLdb.connect(host=host, port=port, user=user, passwd=password, database=database)
#mycursor = mydb.cursor()

diff_algs = {
        "cos": td.cosine,
        "hamming": td.hamming,     # textdistance.hamming.distance('test', 'text') or textdistance.hamming.normalized_distance('test', 'text')
        #"damerau_levenshtein": td.damerau_levenshtein,  # too expensive in ram and cycles
        "jaccard": td.jaccard,
        "jaro": td.jaro,
        "jaro_winkler": td.jaro_winkler,
        "bag": td.bag,
        "editex": td.editex,
    }

"""# The function we will be using is `get_commits`

It will do the heavy lifting of reading the correct database tables and converting that information into DataFrame form.

**Warning**: this can take some time, e.g., for a table with 333K rows, roughly 4 minutes.
"""

"""# Compact alias author names

This is an optional step but leads to better results later. On many repos, the same human developer will have more than one name. We will get more accurate results later if we map all the aliases of a single author to a single name. That is what function below does. Note that it relies on the fuzzywuzzy library for doing string matching. And within fuzzywuzzy, it relies on the cos distance (1 - cosine similarity).

## Caveat

Unfortunately, this simple alias mapping can go awry if we ever really need to use the `author_id` field to look up other information. For instance, we might rightfully find that `jsmith` and `j_smith` are the same developer. The problem is that each will have its own unique id, i.e., the database does not know they are the same. If we replace all occurences of `jsmith` with `j_smith` in the commits table, we will have lost the links to the id of `jsmith`. As a compromise, a new column is added that lists the alias `author_username`s found for each user. It is assumed from this, you can get from `author_username` to `author_id` using other database functions.

For our purposes in this notebook, we only care about `author_username`.
"""


#for def of WRatio see https://github.com/seatgeek/thefuzz/blob/04deff5cc280e034d0344dc9f8731399ecd207cd/thefuzz/fuzz.py#L222 

def score_author_list(author_list, scorer=fuzz.WRatio) -> dict:
  """
        Use fuzzy matching to identify multiple different names that likely belong to the same developer.
  """
  unique_list = list(set(author_list))  #get unique names  - likely includes aliases

  #For each name (might be an alias), list a score for all the names matching that name.
  #Note that the list will be of form [(name1, score1), (name2, score2), ...] in descending order of score.
  #The first item in this list will be the actual name so will have a score of 100, they are the same. All items
  #after that will be other names seen in the list.
  results = {}
  for name in unique_list:
    ratio = process.extract(name, unique_list, limit=10, scorer=scorer) 
    results[name] = ratio  #ratio will be of form [(name1, score1), (name2, score2), ...] in descending order of score.

  return results

#assumes score_author_list has been run to produce fuzzy_matching_results
    
def set_unique_authors(commits_table, fuzzy_matching_results:dict, threshold=70):
  results = fuzzy_matching_results  #just a rename to shorten
  real_names = {}  #used to hold other fields for each base name end up using
  new_df = commits_table.copy()
  new_df['alias'] = ''
  for name in results.keys():
    if name in set(new_df.author_username.to_list()):
        for alias,score in results[name][1:]:    #note the [1:] skips over first, which is always the base name
          if score<threshold: break              #scores are listed in descending order so once score<threshold we can stop looking.

          #now have an alias for name - the alias name has score>=threshold.

          #next, capture the other columns that go along with the base name in the real_names dict. We will use this later to fill in values.
          name_df = new_df.query('author_username == @name').reset_index(drop=True)
          author_email = name_df.loc[0, 'author_email']
          author_id = name_df.loc[0, 'author_id']
          author_name = name_df.loc[0, 'author_name']
          author_url = name_df.loc[0, 'author_url']
          real_names[name] = dict(author_email=author_email, author_id=author_id, author_name=author_name, author_url=author_url, alias= alias)

          #replace the alias with the base name. First replace in Series, then reset column to Series.
          new_col = new_df['author_username'].replace({alias: name})  #new_col is a Series
          new_df['author_username'] = new_col
          #note that once we do this replace, the alias no longer appears in the table. So we will skip over it at top of loop.

  #At this point, the author_username column has non-aliased (base) names. But we still need to go back and clean up the
  #other columns associated with each base name. Make sure they all align with the base name in author_username.
  for name in real_names.keys():
      others = real_names[name]  #other columns for name
      for key in others.keys():
        new_df.loc[new_df['author_username']==name, key] = others[key]

  return new_df


"""##note on branch

some use main, some use master
"""

def compute_text_distance(diff_body, diff_fn):
  lines_list = diff_body.split('\n')
  # Include a summary of the changes, e.g., for one set of diffs, produce '--++-+-+--++--++-+--'
  summary, old, new = "", "", ""
  for line in lines_list:
    #check if line signals whole file change, e.g., move or rename of file.
    if line[:4] in ['+++ ', '--- ']: continue  #skip over file change lines
    if line.startswith("-"):
        summary += "-"
        if len(line)==1:
          old += ' '  #kind of a kluge. A single - signifies removing a blank line. Using a space to stand in for \n
        else:
          old += line[1:]  #skip over - char
    elif line.startswith("+"):
        summary += "+"
        if len(line)==1:
          new += ' '  #kind of a kluge. A single + signifies adding a blank line. Using a space to stand in for \n
        else:
          new += line[1:]  #skip over + char
  #print(f'{summary=}')  #for debugging

  #compute the distance metric. Be careful with either string being empty, signifying a blank line being added or removed.
  #will give diff of 0. To avoid, changed '' to ' '.
  diff = diff_fn(old if old else ' ', new if new else ' ')
  return diff


# #commit_datetime	commit_branch	author_id	author_username	diff_file_path	diff_body

def compute_busfactor(mycursor, repo_name):

  commits_df = get_commits(repo_name, mycursor)

  commits_df.head()

  fuzzy_match = score_author_list(commits_df.author_username.to_list())
  #fuzzy_match

  compact_df = set_unique_authors(commits_df, fuzzy_match)
  set(compact_df.author_username)

  #compact_df

  main_commits_df = compact_df[compact_df['commit_branch'].str.contains('main', regex=False)]

  len(main_commits_df), len(compact_df)  #main commits versus all commits

  drop_columns = 'project_id  project_name  project_last_updated  project_source_url  project_fork_of_id  project_child_of_id commit_id  commit_sha commit_message  author_name author_email  author_url  diff_language short_branch alias'.split()
  main_commits_df.drop(columns=drop_columns, inplace=True)
  main_commits_df.head()

  main_commits_numpy = main_commits_df.to_numpy()
  #main_commits_numpy[:5]

  bus_dictionary = dict()

  for row in main_commits_numpy:
    the_author = row[3]
    the_file = row[4]
    the_diff = row[5]

    cos_distance = compute_text_distance(the_diff, td.cosine)
    if not the_file in bus_dictionary:
      bus_dictionary[the_file] = []
    bus_dictionary[the_file] += [(the_author, cos_distance)]

  #bus_dictionary

  complete_bus = {}
  for key,value in bus_dictionary.items():
    dev_dict = {}
    for name,dist in value:
      if name not in dev_dict: dev_dict[name] = 0
      dev_dict[name] += dist
    complete_bus[key] = dev_dict

  return complete_bus